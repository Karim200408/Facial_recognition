{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByR98vK7Pap-",
        "outputId": "d7e63108-84ed-4e24-c1e7-a16cccc00eda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.11.0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "print(cv2.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get cv2 default haarcascade directory\n",
        "data_dir = cv2.data.haarcascades\n",
        "\n",
        "# Define paths to different haarcascade models\n",
        "cascade_names = {\n",
        "    \"face\": \"haarcascade_frontalface_default.xml\",\n",
        "    \"eyes\": \"haarcascade_eye.xml\"\n",
        "    # \"mouth\": \"haarcascade_mcs_mouth.xml\",\n",
        "    # \"nose\": \"haarcascade_mcs_nose.xml\"\n",
        "}\n",
        "cascade_path = {roi: os.path.join(data_dir, filename) for roi, filename in cascade_names.items()}\n",
        "\n",
        "print(cascade_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1qbLsRmP_Hk",
        "outputId": "ac17b6d0-3e9f-468a-f44f-1189e63705b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'face': '/usr/local/lib/python3.11/dist-packages/cv2/data/haarcascade_frontalface_default.xml', 'eyes': '/usr/local/lib/python3.11/dist-packages/cv2/data/haarcascade_eye.xml'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#-- 1. Load the cascades\n",
        "cascades = {}\n",
        "for roi, path in cascade_path.items():\n",
        "    if not os.path.exists(path): # Check if the file exists\n",
        "        print(f\"--(!)Warning: {roi} cascade not found at {path}, Skipping...\")\n",
        "        continue # Skip cascade if file is missing\n",
        "\n",
        "    classifier = cv2.CascadeClassifier()\n",
        "    if not classifier.load(path):\n",
        "        print(f'--(X)Error loading {roi} cascade at {path}')\n",
        "        exit(0)\n",
        "    cascades[roi] = classifier\n",
        "print(\"--(*)Haar cascades loaded successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tN3lirCaQG7J",
        "outputId": "c793cce4-4eeb-4963-cfad-6d678d4c7078"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--(*)Haar cascades loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def detect(frame):\n",
        "    # Convert the frame into grayscale and equalize\n",
        "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    frame_gray = cv2.equalizeHist(frame_gray)\n",
        "\n",
        "    #-- Detect faces\n",
        "    faces = cascades['face'].detectMultiScale(\n",
        "        frame_gray,\n",
        "        scaleFactor=1.05,\n",
        "        minNeighbors=5,\n",
        "        minSize=(30, 30),\n",
        "        flags=cv2.CASCADE_SCALE_IMAGE\n",
        "        )\n",
        "    # Loop over the bounding box for each face\n",
        "    for (x,y,w,h) in faces:\n",
        "        # Obtain the center and draw an ellipse around the face\n",
        "        center = (x + w//2, y + h//2)\n",
        "        frame = cv2.ellipse(frame, center, (w//2, h//2), 0, 0, 360, (255, 0, 255), 4)\n",
        "        face_roi = frame_gray[y:y+h, x:x+w]\n",
        "        #-- In each face, detect eyes\n",
        "        eyes = cascades['eyes'].detectMultiScale(\n",
        "            face_roi,\n",
        "            scaleFactor=1.1,\n",
        "            minNeighbors=10,\n",
        "            minSize=(15, 15),\n",
        "            flags=cv2.CASCADE_SCALE_IMAGE\n",
        "            )\n",
        "        # Loop over the bounding box for the eyes relative to the original frame dimensions\n",
        "        for (x2, y2, w2, h2) in eyes:\n",
        "            ptA = (x + x2, y + y2)\n",
        "            ptB = (x + x2 + w2, y + y2 + h2)\n",
        "            # Draw rectangles around the eyes\n",
        "            cv2.rectangle(frame, ptA, ptB, (0, 0, 255), 2)\n",
        "    cv2.imshow('Capture - Face detection', frame) # Show frame"
      ],
      "metadata": {
        "id": "GCHM-BjxQKcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#-- 2. Read the video stream\n",
        "cap = cv2.VideoCapture(1)\n",
        "if not cap.isOpened:\n",
        "    print(\"--(X)Error opening video capture\")\n",
        "    exit(0)\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if frame is None:\n",
        "        print(\"--(!) No captured frame -- Break!\")\n",
        "        break\n",
        "    detect(frame)\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cv2.destroyAllWindows() # Clean-up"
      ],
      "metadata": {
        "id": "Ci1xOP4EQOX3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "d216e8bf-73de-4be0-a72f-15fb07d98357"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--(!) No captured frame -- Break!\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "OpenCV(4.11.0) /io/opencv/modules/highgui/src/window.cpp:1295: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-8e1bb6d127fd>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Clean-up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.11.0) /io/opencv/modules/highgui/src/window.cpp:1295: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n"
          ]
        }
      ]
    }
  ]
}